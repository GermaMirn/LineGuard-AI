#!/usr/bin/env python3
"""
–ê–ì–†–ï–°–°–ò–í–ù–ê–Ø –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∫–ª–∞—Å—Å–æ–≤ —Å –º–∞–ª—ã–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º –ø—Ä–∏–º–µ—Ä–æ–≤
–°–æ–∑–¥–∞—ë—Ç x8 –±–æ–ª—å—à–µ –æ–±—É—á–∞—é—â–∏—Ö –ø—Ä–∏–º–µ—Ä–æ–≤ —Å —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–Ω—ã–º–∏ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏—è–º–∏
"""

import os
import random
from pathlib import Path
from typing import List, Tuple
import cv2
import numpy as np

# –ö–ª–∞—Å—Å—ã –¥–ª—è –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–∏
MINORITY_CLASSES = [6, 7]  # nest, safety_sign

# –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–æ–ø–∏–π –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
AUGMENTATION_FACTOR = 5  # x5 –±–æ–ª—å—à–µ –¥–∞–Ω–Ω—ã—Ö!

# –ù–∞—Å—Ç—Ä–æ–π–∫–∏
ROTATION_RANGE = (-25, 25)  # –ë–æ–ª–µ–µ –∞–≥—Ä–µ—Å—Å–∏–≤–Ω—ã–π –ø–æ–≤–æ—Ä–æ—Ç
BRIGHTNESS_RANGE = (0.6, 1.4)  # 60%-140%
CONTRAST_RANGE = (0.7, 1.3)  # 70%-130%
SATURATION_RANGE = (0.7, 1.3)
HUE_SHIFT_RANGE = (-10, 10)
BLUR_KERNEL_RANGE = (3, 7)
NOISE_RANGE = (0, 15)
ZOOM_RANGE = (0.9, 1.1)  # Zoom in/out 90%-110%


def read_yolo_label(label_path: Path) -> List[Tuple[int, float, float, float, float]]:
    """–ß–∏—Ç–∞–µ—Ç YOLO label —Ñ–∞–π–ª"""
    if not label_path.exists():
        return []

    boxes = []
    with open(label_path, 'r') as f:
        for line in f:
            parts = line.strip().split()
            if len(parts) >= 5:
                class_id = int(parts[0])
                x_center = float(parts[1])
                y_center = float(parts[2])
                width = float(parts[3])
                height = float(parts[4])
                boxes.append((class_id, x_center, y_center, width, height))
    return boxes


def write_yolo_label(label_path: Path, boxes: List[Tuple[int, float, float, float, float]]):
    """–ó–∞–ø–∏—Å—ã–≤–∞–µ—Ç YOLO label —Ñ–∞–π–ª —Å –∫–ª–∏–ø–∏–Ω–≥–æ–º –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç"""
    with open(label_path, 'w') as f:
        for box in boxes:
            class_id, x_center, y_center, width, height = box
            # –ö–ª–∏–ø–∏–Ω–≥ –¥–æ [0, 1]
            x_center = max(0.0, min(1.0, x_center))
            y_center = max(0.0, min(1.0, y_center))
            width = max(0.0, min(1.0, width))
            height = max(0.0, min(1.0, height))
            f.write(f"{class_id} {x_center:.6f} {y_center:.6f} {width:.6f} {height:.6f}\n")


def rotate_image_and_boxes(image: np.ndarray, boxes: List[Tuple], angle: float) -> Tuple[np.ndarray, List[Tuple]]:
    """–ü–æ–≤–æ—Ä–æ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏ bbox"""
    h, w = image.shape[:2]
    center = (w // 2, h // 2)

    M = cv2.getRotationMatrix2D(center, angle, 1.0)
    rotated = cv2.warpAffine(image, M, (w, h), flags=cv2.INTER_LINEAR, borderMode=cv2.BORDER_REFLECT)

    return rotated, boxes


def adjust_brightness_contrast(image: np.ndarray, brightness: float, contrast: float) -> np.ndarray:
    """–Ø—Ä–∫–æ—Å—Ç—å –∏ –∫–æ–Ω—Ç—Ä–∞—Å—Ç"""
    img = cv2.convertScaleAbs(image, alpha=contrast, beta=0)
    img = cv2.convertScaleAbs(img, alpha=brightness, beta=0)
    return img


def adjust_hsv(image: np.ndarray, saturation: float, hue_shift: int) -> np.ndarray:
    """–ò–∑–º–µ–Ω–µ–Ω–∏–µ HSV (–Ω–∞—Å—ã—â–µ–Ω–Ω–æ—Å—Ç—å –∏ –æ—Ç—Ç–µ–Ω–æ–∫)"""
    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV).astype(np.float32)

    # Saturation
    hsv[:, :, 1] = np.clip(hsv[:, :, 1] * saturation, 0, 255)

    # Hue shift
    hsv[:, :, 0] = (hsv[:, :, 0] + hue_shift) % 180

    return cv2.cvtColor(hsv.astype(np.uint8), cv2.COLOR_HSV2BGR)


def add_blur(image: np.ndarray, kernel_size: int) -> np.ndarray:
    """–†–∞–∑–º—ã—Ç–∏–µ"""
    if kernel_size % 2 == 0:
        kernel_size += 1
    return cv2.GaussianBlur(image, (kernel_size, kernel_size), 0)


def add_sharpen(image: np.ndarray) -> np.ndarray:
    """–ü–æ–≤—ã—à–µ–Ω–∏–µ —Ä–µ–∑–∫–æ—Å—Ç–∏"""
    kernel = np.array([[-1, -1, -1],
                       [-1,  9, -1],
                       [-1, -1, -1]])
    return cv2.filter2D(image, -1, kernel)


def add_noise(image: np.ndarray, noise_level: float) -> np.ndarray:
    """–ì–∞—É—Å—Å–æ–≤ —à—É–º"""
    if noise_level == 0:
        return image

    noise = np.random.normal(0, noise_level, image.shape).astype(np.int16)
    noisy = np.clip(image.astype(np.int16) + noise, 0, 255).astype(np.uint8)
    return noisy


def apply_clahe(image: np.ndarray) -> np.ndarray:
    """CLAHE - —É–ª—É—á—à–µ–Ω–∏–µ –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ –∫–æ–Ω—Ç—Ä–∞—Å—Ç–∞"""
    lab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
    lab[:, :, 0] = clahe.apply(lab[:, :, 0])
    return cv2.cvtColor(lab, cv2.COLOR_LAB2BGR)


def zoom_image_and_boxes(image: np.ndarray, boxes: List[Tuple], zoom: float) -> Tuple[np.ndarray, List[Tuple]]:
    """Zoom in/out —Å –∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∫–æ–π bbox"""
    h, w = image.shape[:2]

    if zoom == 1.0:
        return image, boxes

    # –í—ã—á–∏—Å–ª—è–µ–º –Ω–æ–≤—ã–π —Ä–∞–∑–º–µ—Ä
    new_h = int(h / zoom)
    new_w = int(w / zoom)

    # Crop —Ü–µ–Ω—Ç—Ä
    y1 = (h - new_h) // 2
    x1 = (w - new_w) // 2
    y2 = y1 + new_h
    x2 = x1 + new_w

    cropped = image[y1:y2, x1:x2]

    # Resize –æ–±—Ä–∞—Ç–Ω–æ –∫ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–º—É —Ä–∞–∑–º–µ—Ä—É
    zoomed = cv2.resize(cropped, (w, h), interpolation=cv2.INTER_LINEAR)

    # Bbox –æ—Å—Ç–∞—é—Ç—Å—è –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ —Ü–µ–Ω—Ç—Ä–∞, –ø–æ—ç—Ç–æ–º—É –Ω–µ —Ç—Ä–æ–≥–∞–µ–º
    return zoomed, boxes


def flip_horizontal(image: np.ndarray, boxes: List[Tuple]) -> Tuple[np.ndarray, List[Tuple]]:
    """–ì–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª—å–Ω–æ–µ –æ—Ç—Ä–∞–∂–µ–Ω–∏–µ"""
    flipped_img = cv2.flip(image, 1)

    flipped_boxes = []
    for class_id, x_center, y_center, width, height in boxes:
        new_x_center = 1.0 - x_center
        flipped_boxes.append((class_id, new_x_center, y_center, width, height))

    return flipped_img, flipped_boxes


def flip_vertical(image: np.ndarray, boxes: List[Tuple]) -> Tuple[np.ndarray, List[Tuple]]:
    """–í–µ—Ä—Ç–∏–∫–∞–ª—å–Ω–æ–µ –æ—Ç—Ä–∞–∂–µ–Ω–∏–µ"""
    flipped_img = cv2.flip(image, 0)

    flipped_boxes = []
    for class_id, x_center, y_center, width, height in boxes:
        new_y_center = 1.0 - y_center
        flipped_boxes.append((class_id, x_center, new_y_center, width, height))

    return flipped_img, flipped_boxes


def add_shadow(image: np.ndarray) -> np.ndarray:
    """–î–æ–±–∞–≤–ª—è–µ—Ç —Å–ª—É—á–∞–π–Ω—É—é —Ç–µ–Ω—å"""
    h, w = image.shape[:2]

    # –°–ª—É—á–∞–π–Ω–∞—è —Ç–µ–Ω—å
    top_y = random.randint(0, h // 2)
    bottom_y = random.randint(h // 2, h)

    shadow_mask = np.zeros((h, w), dtype=np.float32)
    shadow_mask[top_y:bottom_y, :] = random.uniform(0.4, 0.7)

    shadow_mask = cv2.GaussianBlur(shadow_mask, (51, 51), 0)

    shadowed = image.copy().astype(np.float32)
    shadowed = shadowed * (1 - shadow_mask[:, :, np.newaxis])

    return np.clip(shadowed, 0, 255).astype(np.uint8)


def augment_image(image_path: Path, label_path: Path, output_image_path: Path, output_label_path: Path, aug_id: int):
    """–ü—Ä–∏–º–µ–Ω—è–µ—Ç –∞–≥—Ä–µ—Å—Å–∏–≤–Ω—É—é –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏—é"""
    # –ß–∏—Ç–∞–µ–º
    image = cv2.imread(str(image_path))
    if image is None:
        return False

    boxes = read_yolo_label(label_path)
    if not boxes:
        return False

    augmented_img = image.copy()
    augmented_boxes = boxes.copy()

    # === –ù–ê–ë–û–† –¢–†–ê–ù–°–§–û–†–ú–ê–¶–ò–ô (—Ä–∞–Ω–¥–æ–º–Ω—ã–π –≤—ã–±–æ—Ä) ===

    # 1. –ü–æ–≤–æ—Ä–æ—Ç (70% –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å)
    if random.random() > 0.3:
        angle = random.uniform(*ROTATION_RANGE)
        augmented_img, augmented_boxes = rotate_image_and_boxes(augmented_img, augmented_boxes, angle)

    # 2. Flip –≥–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª—å–Ω—ã–π (50%)
    if random.random() > 0.5:
        augmented_img, augmented_boxes = flip_horizontal(augmented_img, augmented_boxes)

    # 3. Flip –≤–µ—Ä—Ç–∏–∫–∞–ª—å–Ω—ã–π (20%)
    if random.random() > 0.8:
        augmented_img, augmented_boxes = flip_vertical(augmented_img, augmented_boxes)

    # 4. –Ø—Ä–∫–æ—Å—Ç—å –∏ –∫–æ–Ω—Ç—Ä–∞—Å—Ç (–≤—Å–µ–≥–¥–∞)
    brightness = random.uniform(*BRIGHTNESS_RANGE)
    contrast = random.uniform(*CONTRAST_RANGE)
    augmented_img = adjust_brightness_contrast(augmented_img, brightness, contrast)

    # 5. HSV (70%)
    if random.random() > 0.3:
        saturation = random.uniform(*SATURATION_RANGE)
        hue_shift = random.randint(*HUE_SHIFT_RANGE)
        augmented_img = adjust_hsv(augmented_img, saturation, hue_shift)

    # 6. Blur –ò–õ–ò Sharpen (50%)
    if random.random() > 0.5:
        if random.random() > 0.5:
            kernel_size = random.choice([3, 5, 7])
            augmented_img = add_blur(augmented_img, kernel_size)
        else:
            augmented_img = add_sharpen(augmented_img)

    # 7. Noise (30%)
    if random.random() > 0.7:
        noise_level = random.uniform(*NOISE_RANGE)
        augmented_img = add_noise(augmented_img, noise_level)

    # 8. CLAHE (40%)
    if random.random() > 0.6:
        augmented_img = apply_clahe(augmented_img)

    # 9. Zoom (30%)
    if random.random() > 0.7:
        zoom = random.uniform(*ZOOM_RANGE)
        augmented_img, augmented_boxes = zoom_image_and_boxes(augmented_img, augmented_boxes, zoom)

    # 10. Shadow (20%)
    if random.random() > 0.8:
        augmented_img = add_shadow(augmented_img)

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º
    cv2.imwrite(str(output_image_path), augmented_img)
    write_yolo_label(output_label_path, augmented_boxes)

    return True


def main():
    dataset_dir = Path(__file__).parent.parent / 'dataset_8classes'

    if not dataset_dir.exists():
        print(f"‚ùå –î–∞—Ç–∞—Å–µ—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω: {dataset_dir}")
        return

    print("üöÄ –ê–ì–†–ï–°–°–ò–í–ù–ê–Ø –ê–£–ì–ú–ï–ù–¢–ê–¶–ò–Ø (x5 –∫–æ–ø–∏–π)...")
    print(f"   –ö–ª–∞—Å—Å—ã: {MINORITY_CLASSES}")
    print()

    total_created = 0

    for split in ['train', 'val', 'test']:
        images_dir = dataset_dir / 'images' / split
        labels_dir = dataset_dir / 'labels' / split

        if not images_dir.exists() or not labels_dir.exists():
            continue

        print(f"üìÇ {split}...")

        # –ù–∞—Ö–æ–¥–∏–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Å –∫–ª–∞—Å—Å–∞–º–∏ 6, 7
        images_to_augment = []

        for label_file in labels_dir.glob('*.txt'):
            boxes = read_yolo_label(label_file)
            has_minority = any(class_id in MINORITY_CLASSES for class_id, _, _, _, _ in boxes)

            if has_minority:
                image_name = label_file.stem
                for ext in ['.jpg', '.JPG', '.jpeg', '.png']:
                    image_path = images_dir / f"{image_name}{ext}"
                    if image_path.exists():
                        images_to_augment.append((image_path, label_file))
                        break

        print(f"   –ù–∞–π–¥–µ–Ω–æ: {len(images_to_augment)}")

        if not images_to_augment:
            continue

        # –ê—É–≥–º–µ–Ω—Ç–∞—Ü–∏—è
        augmented_count = 0

        for image_path, label_path in images_to_augment:
            base_name = image_path.stem
            ext = image_path.suffix

            for i in range(AUGMENTATION_FACTOR):
                aug_name = f"{base_name}_adv{i}"
                output_image = images_dir / f"{aug_name}{ext}"
                output_label = labels_dir / f"{aug_name}.txt"

                if augment_image(image_path, label_path, output_image, output_label, i):
                    augmented_count += 1

                    if augmented_count % 100 == 0:
                        print(f"   ‚úÖ {augmented_count}")

        print(f"   ‚úÖ –°–æ–∑–¥–∞–Ω–æ: {augmented_count}\n")
        total_created += augmented_count

    print(f"üéâ –ì–û–¢–û–í–û! –°–æ–∑–¥–∞–Ω–æ {total_created} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π!")
    print(f"\nüìä –¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏:")
    print(f"   ‚Ä¢ –ü–æ–≤–æ—Ä–æ—Ç: ¬±25¬∞")
    print(f"   ‚Ä¢ Flip: –≥–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª—å–Ω—ã–π + –≤–µ—Ä—Ç–∏–∫–∞–ª—å–Ω—ã–π")
    print(f"   ‚Ä¢ –Ø—Ä–∫–æ—Å—Ç—å: 60%-140%")
    print(f"   ‚Ä¢ –ö–æ–Ω—Ç—Ä–∞—Å—Ç: 70%-130%")
    print(f"   ‚Ä¢ HSV: –Ω–∞—Å—ã—â–µ–Ω–Ω–æ—Å—Ç—å + –æ—Ç—Ç–µ–Ω–æ–∫")
    print(f"   ‚Ä¢ Blur/Sharpen")
    print(f"   ‚Ä¢ Noise: –≥–∞—É—Å—Å–æ–≤ —à—É–º")
    print(f"   ‚Ä¢ CLAHE: —É–ª—É—á—à–µ–Ω–∏–µ –∫–æ–Ω—Ç—Ä–∞—Å—Ç–∞")
    print(f"   ‚Ä¢ Zoom: 90%-110%")
    print(f"   ‚Ä¢ Shadow: —Å–ª—É—á–∞–π–Ω—ã–µ —Ç–µ–Ω–∏")


if __name__ == '__main__':
    main()

