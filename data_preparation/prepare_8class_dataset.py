"""
–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞ –¥–ª—è 8 –∫–ª–∞—Å—Å–æ–≤:
- –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –±–µ—Ä—ë–º –∏–∑ real_dataset/
- –ú–µ—Ç–∫–∏ –±–µ—Ä—ë–º –∏–∑ dataset/labels/ (—Å—Ç–∞—Ä—ã–π –¥–∞—Ç–∞—Å–µ—Ç)
- –°–æ–∑–¥–∞—ë–º –Ω–æ–≤—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É dataset_8classes/
"""
import os
import shutil
from pathlib import Path
from collections import defaultdict
import random
from sklearn.model_selection import train_test_split

# –ú–∞–ø–ø–∏–Ω–≥ —Å—Ç–∞—Ä—ã—Ö –∫–ª–∞—Å—Å–æ–≤ (6) –≤ –Ω–æ–≤—ã–µ (8)
# TODO: –£—Ç–æ—á–Ω–∏—Ç–µ –º–∞–ø–ø–∏–Ω–≥ –∫–ª–∞—Å—Å–æ–≤
CLASS_MAPPING = {
    0: 0,  # vibration_damper -> vibration_damper
    1: 1,  # festoon_insulators -> festoon_insulators
    2: 2,  # traverse -> traverse
    3: 3,  # bad_insulator -> bad_insulator
    4: 4,  # damaged_insulator -> damaged_insulator
    5: 5,  # polymer_insulators -> polymer_insulators
    # –ö–ª–∞—Å—Å—ã 6 –∏ 7 –±—É–¥—É—Ç –¥–æ–±–∞–≤–ª–µ–Ω—ã –≤—Ä—É—á–Ω—É—é –∏–ª–∏ —á–µ—Ä–µ–∑ –Ω–æ–≤—É—é —Ä–∞–∑–º–µ—Ç–∫—É
}

def get_image_extensions():
    """–í—Å–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π"""
    return ['.jpg', '.JPG', '.jpeg', '.JPEG', '.png', '.PNG', '.tiff', '.TIFF', '.bmp', '.BMP']

def find_matching_label(image_path, labels_dir):
    """
    –ü–æ–∏—Å–∫ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–µ–≥–æ label —Ñ–∞–π–ª–∞ –¥–ª—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
    
    Args:
        image_path: –ø—É—Ç—å –∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é
        labels_dir: –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è —Å –º–µ—Ç–∫–∞–º–∏ –∏–∑ —Å—Ç–∞—Ä–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞
    
    Returns:
        Path –∫ label —Ñ–∞–π–ª—É –∏–ª–∏ None
    """
    image_name = image_path.stem  # –ò–º—è –±–µ–∑ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è
    
    # –ò—â–µ–º —Ä–µ–∫—É—Ä—Å–∏–≤–Ω–æ –≤–æ –≤—Å–µ—Ö –ø–æ–¥–ø–∞–ø–∫–∞—Ö labels_dir
    for label_file in labels_dir.rglob(f"{image_name}.txt"):
        return label_file
    
    # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ —Ç–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ, –ø—Ä–æ–±—É–µ–º –ø–æ–∏—Å–∫ –ø–æ —á–∞—Å—Ç–∏ –∏–º–µ–Ω–∏
    # (–Ω–∞ —Å–ª—É—á–∞–π –µ—Å–ª–∏ –∏–º–µ–Ω–∞ –Ω–µ–º–Ω–æ–≥–æ –æ—Ç–ª–∏—á–∞—é—Ç—Å—è)
    for label_file in labels_dir.rglob("*.txt"):
        if image_name.lower() in label_file.stem.lower():
            return label_file
    
    return None

def convert_label_classes(label_path, class_mapping):
    """
    –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –∫–ª–∞—Å—Å–æ–≤ –≤ label —Ñ–∞–π–ª–µ –ø–æ –º–∞–ø–ø–∏–Ω–≥—É
    
    Args:
        label_path: –ø—É—Ç—å –∫ label —Ñ–∞–π–ª—É
        class_mapping: —Å–ª–æ–≤–∞—Ä—å –º–∞–ø–ø–∏–Ω–≥–∞ —Å—Ç–∞—Ä—ã—Ö –∫–ª–∞—Å—Å–æ–≤ –≤ –Ω–æ–≤—ã–µ
    
    Returns:
        –°–ø–∏—Å–æ–∫ —Å—Ç—Ä–æ–∫ —Å –Ω–æ–≤—ã–º–∏ –º–µ—Ç–∫–∞–º–∏
    """
    new_labels = []
    
    with open(label_path, 'r') as f:
        for line in f:
            parts = line.strip().split()
            if len(parts) < 5:
                continue
            
            old_class = int(parts[0])
            
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –∫–ª–∞—Å—Å –µ—Å–ª–∏ –µ—Å—Ç—å –≤ –º–∞–ø–ø–∏–Ω–≥–µ
            if old_class in class_mapping:
                new_class = class_mapping[old_class]
                # –ó–∞–º–µ–Ω—è–µ–º –∫–ª–∞—Å—Å, –æ—Å—Ç–∞–ª—å–Ω–æ–µ –æ—Å—Ç–∞–≤–ª—è–µ–º –∫–∞–∫ –µ—Å—Ç—å
                new_line = f"{new_class} {' '.join(parts[1:])}\n"
                new_labels.append(new_line)
            # –ï—Å–ª–∏ –∫–ª–∞—Å—Å–∞ –Ω–µ—Ç –≤ –º–∞–ø–ø–∏–Ω–≥–µ, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º (–∏–ª–∏ –º–æ–∂–Ω–æ –æ—Å—Ç–∞–≤–∏—Ç—å –∫–∞–∫ –µ—Å—Ç—å)
    
    return new_labels

def prepare_dataset(real_dataset_dir, old_labels_dir, output_dir, train_ratio=0.8, val_ratio=0.1, test_ratio=0.1, random_seed=42):
    """
    –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞ –¥–ª—è 8 –∫–ª–∞—Å—Å–æ–≤
    
    Args:
        real_dataset_dir: –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è —Å –Ω–æ–≤—ã–º–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏ (real_dataset/)
        old_labels_dir: –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è —Å –º–µ—Ç–∫–∞–º–∏ –∏–∑ —Å—Ç–∞—Ä–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞ (dataset/labels/)
        output_dir: –≤—ã—Ö–æ–¥–Ω–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è (dataset_8classes/)
        train_ratio: –¥–æ–ª—è –æ–±—É—á–∞—é—â–µ–π –≤—ã–±–æ—Ä–∫–∏
        val_ratio: –¥–æ–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–æ–π –≤—ã–±–æ—Ä–∫–∏
        test_ratio: –¥–æ–ª—è —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–∏
        random_seed: seed –¥–ª—è –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç–∏
    """
    random.seed(random_seed)
    
    real_dataset_path = Path(real_dataset_dir)
    old_labels_path = Path(old_labels_dir)
    output_path = Path(output_dir)
    
    # –û—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä–æ–π –≤—ã—Ö–æ–¥–Ω–æ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
    if output_path.exists():
        print("üßπ –û—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä–æ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏...")
        shutil.rmtree(output_path)
    
    # –°–æ–∑–¥–∞—ë–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π
    print("üìÅ –°–æ–∑–¥–∞–Ω–∏–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π...")
    for split in ['train', 'val', 'test']:
        (output_path / 'images' / split).mkdir(parents=True, exist_ok=True)
        (output_path / 'labels' / split).mkdir(parents=True, exist_ok=True)
    
    # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏–∑ real_dataset (–≤–∫–ª—é—á–∞—è –ø–æ–¥–ø–∞–ø–∫–∏)
    print("\nüîç –°–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –≤ real_dataset...")
    all_images = []
    extensions = get_image_extensions()
    
    for img_file in real_dataset_path.rglob("*"):
        if img_file.is_file() and img_file.suffix in extensions:
            all_images.append(img_file)
    
    print(f"   –ù–∞–π–¥–µ–Ω–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π: {len(all_images)}")
    
    # –§–∏–ª—å—Ç—Ä—É–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è, –¥–ª—è –∫–æ—Ç–æ—Ä—ã—Ö –µ—Å—Ç—å –º–µ—Ç–∫–∏
    print("\nüè∑Ô∏è  –ü–æ–∏—Å–∫ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏—Ö –º–µ—Ç–æ–∫...")
    images_with_labels = []
    images_without_labels = []
    
    for img_path in all_images:
        label_path = find_matching_label(img_path, old_labels_path)
        if label_path:
            images_with_labels.append((img_path, label_path))
        else:
            images_without_labels.append(img_path)
    
    print(f"   –° –º–µ—Ç–∫–∞–º–∏: {len(images_with_labels)}")
    print(f"   –ë–µ–∑ –º–µ—Ç–æ–∫: {len(images_without_labels)}")
    
    if len(images_with_labels) == 0:
        print("\n‚ùå –û–®–ò–ë–ö–ê: –ù–µ –Ω–∞–π–¥–µ–Ω–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —Å —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–º–∏ –º–µ—Ç–∫–∞–º–∏!")
        print("   –ü—Ä–æ–≤–µ—Ä—å—Ç–µ, —á—Ç–æ –∏–º–µ–Ω–∞ —Ñ–∞–π–ª–æ–≤ –≤ real_dataset/ —Å–æ–≤–ø–∞–¥–∞—é—Ç —Å –∏–º–µ–Ω–∞–º–∏ –≤ dataset/labels/")
        return
    
    # –†–∞–∑–¥–µ–ª—è–µ–º –Ω–∞ train/val/test
    print("\nüìä –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ train/val/test...")
    train_data, temp_data = train_test_split(
        images_with_labels,
        test_size=(1 - train_ratio),
        random_state=random_seed
    )
    
    val_size = val_ratio / (val_ratio + test_ratio)
    val_data, test_data = train_test_split(
        temp_data,
        test_size=(1 - val_size),
        random_state=random_seed
    )
    
    splits = {
        'train': train_data,
        'val': val_data,
        'test': test_data
    }
    
    print(f"   Train: {len(train_data)} ({len(train_data)/len(images_with_labels)*100:.1f}%)")
    print(f"   Val:   {len(val_data)} ({len(val_data)/len(images_with_labels)*100:.1f}%)")
    print(f"   Test:  {len(test_data)} ({len(test_data)/len(images_with_labels)*100:.1f}%)")
    
    # –ö–æ–ø–∏—Ä—É–µ–º —Ñ–∞–π–ª—ã –∏ –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –º–µ—Ç–∫–∏
    print("\nüì¶ –ö–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–æ–≤ –∏ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –º–µ—Ç–æ–∫...")
    
    stats = {'total': 0, 'converted': 0, 'skipped': 0}
    
    for split_name, data in splits.items():
        print(f"\n   {split_name}:")
        for img_path, label_path in data:
            # –ö–æ–ø–∏—Ä—É–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
            img_dst = output_path / 'images' / split_name / img_path.name
            shutil.copy2(img_path, img_dst)
            
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –∏ –∫–æ–ø–∏—Ä—É–µ–º –º–µ—Ç–∫—É
            new_labels = convert_label_classes(label_path, CLASS_MAPPING)
            
            if len(new_labels) > 0:
                label_dst = output_path / 'labels' / split_name / (img_path.stem + '.txt')
                with open(label_dst, 'w') as f:
                    f.writelines(new_labels)
                stats['converted'] += 1
            else:
                stats['skipped'] += 1
            
            stats['total'] += 1
        
        print(f"      –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {len(data)} —Ñ–∞–π–ª–æ–≤")
    
    print(f"\n‚úÖ –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞!")
    print(f"   –í—Å–µ–≥–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {stats['total']}")
    print(f"   –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–æ –º–µ—Ç–æ–∫: {stats['converted']}")
    print(f"   –ü—Ä–æ–ø—É—â–µ–Ω–æ (–Ω–µ—Ç –∞–Ω–Ω–æ—Ç–∞—Ü–∏–π): {stats['skipped']}")
    print(f"   –í—ã—Ö–æ–¥–Ω–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è: {output_path}")
    
    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –∫–ª–∞—Å—Å–∞–º
    print("\nüìà –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –∫–ª–∞—Å—Å–∞–º:")
    class_counts = defaultdict(int)
    
    for split_name in ['train', 'val', 'test']:
        label_dir = output_path / 'labels' / split_name
        for label_file in label_dir.glob('*.txt'):
            with open(label_file, 'r') as f:
                for line in f:
                    parts = line.strip().split()
                    if len(parts) >= 5:
                        class_id = int(parts[0])
                        class_counts[class_id] += 1
    
    for class_id in sorted(class_counts.keys()):
        print(f"   –ö–ª–∞—Å—Å {class_id}: {class_counts[class_id]} –∞–Ω–Ω–æ—Ç–∞—Ü–∏–π")

if __name__ == "__main__":
    project_root = Path(__file__).parent.parent
    
    real_dataset_dir = project_root / "real_dataset"
    old_labels_dir = project_root / "dataset" / "labels"
    output_dir = project_root / "dataset_8classes"
    
    print("=" * 60)
    print("–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞ –¥–ª—è 8 –∫–ª–∞—Å—Å–æ–≤")
    print("=" * 60)
    print(f"–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {real_dataset_dir}")
    print(f"–ú–µ—Ç–∫–∏: {old_labels_dir}")
    print(f"–í—ã—Ö–æ–¥: {output_dir}")
    print("=" * 60)
    
    if not real_dataset_dir.exists():
        print(f"‚ùå –û—à–∏–±–∫–∞: –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è {real_dataset_dir} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞!")
        exit(1)
    
    if not old_labels_dir.exists():
        print(f"‚ùå –û—à–∏–±–∫–∞: –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è {old_labels_dir} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞!")
        exit(1)
    
    prepare_dataset(
        real_dataset_dir=real_dataset_dir,
        old_labels_dir=old_labels_dir,
        output_dir=output_dir,
        random_seed=42
    )

