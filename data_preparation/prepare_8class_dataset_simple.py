"""
–£–ø—Ä–æ—â–µ–Ω–Ω–∞—è –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞ –¥–ª—è 8 –∫–ª–∞—Å—Å–æ–≤ –±–µ–∑ sklearn
–ò—Å–ø–æ–ª—å–∑—É–µ—Ç –ø—Ä–æ—Å—Ç–æ–µ random —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ train/val/test
"""
import os
import shutil
from pathlib import Path
from collections import defaultdict
import random

# –ú–∞–ø–ø–∏–Ω–≥ —Å—Ç–∞—Ä—ã—Ö –∫–ª–∞—Å—Å–æ–≤ (6) –≤ –Ω–æ–≤—ã–µ (8)
# –°–Ω–∞—á–∞–ª–∞ –Ω—É–∂–Ω–æ –ø–µ—Ä–µ–∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å dataset/ —á—Ç–æ–±—ã –≤–∫–ª—é—á–∏—Ç—å nest –∏ safety_sign!
CLASS_MAPPING = {
    0: 0,  # vibration_damper -> vibration_damper
    1: 1,  # festoon_insulators -> festoon_insulators
    2: 2,  # traverse -> traverse
    3: 3,  # bad_insulator -> bad_insulator
    4: 4,  # damaged_insulator -> damaged_insulator
    5: 5,  # polymer_insulators -> polymer_insulators
    6: 6,  # nest -> nest (–ù–û–í–´–ô)
    7: 7,  # safety_sign -> safety_sign (–ù–û–í–´–ô)
}

def get_image_extensions():
    """–í—Å–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π"""
    return ['.jpg', '.JPG', '.jpeg', '.JPEG', '.png', '.PNG', '.tiff', '.TIFF', '.bmp', '.BMP']

def find_matching_label(image_path, labels_dir):
    """–ü–æ–∏—Å–∫ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–µ–≥–æ label —Ñ–∞–π–ª–∞ –¥–ª—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è"""
    image_name = image_path.stem
    
    # –ò—â–µ–º —Ä–µ–∫—É—Ä—Å–∏–≤–Ω–æ
    for label_file in labels_dir.rglob(f"{image_name}.txt"):
        return label_file
    
    # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏, –ø—Ä–æ–±—É–µ–º –ø–æ–∏—Å–∫ –ø–æ —á–∞—Å—Ç–∏ –∏–º–µ–Ω–∏
    for label_file in labels_dir.rglob("*.txt"):
        if image_name.lower() in label_file.stem.lower():
            return label_file
    
    return None

def convert_label_classes(label_path, class_mapping):
    """–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –∫–ª–∞—Å—Å–æ–≤ –≤ label —Ñ–∞–π–ª–µ"""
    new_labels = []
    
    with open(label_path, 'r') as f:
        for line in f:
            parts = line.strip().split()
            if len(parts) < 5:
                continue
            
            old_class = int(parts[0])
            
            if old_class in class_mapping:
                new_class = class_mapping[old_class]
                new_line = f"{new_class} {' '.join(parts[1:])}\n"
                new_labels.append(new_line)
    
    return new_labels

def prepare_dataset(real_dataset_dir, old_labels_dir, output_dir, train_ratio=0.8, val_ratio=0.1, test_ratio=0.1, random_seed=42):
    """–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞ –¥–ª—è 8 –∫–ª–∞—Å—Å–æ–≤"""
    random.seed(random_seed)
    
    real_dataset_path = Path(real_dataset_dir)
    old_labels_path = Path(old_labels_dir)
    output_path = Path(output_dir)
    
    # –û—á–∏—Å—Ç–∫–∞
    if output_path.exists():
        print("üßπ –û—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä–æ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏...")
        shutil.rmtree(output_path)
    
    # –°–æ–∑–¥–∞—ë–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É
    print("üìÅ –°–æ–∑–¥–∞–Ω–∏–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π...")
    for split in ['train', 'val', 'test']:
        (output_path / 'images' / split).mkdir(parents=True, exist_ok=True)
        (output_path / 'labels' / split).mkdir(parents=True, exist_ok=True)
    
    # –°–æ–±–∏—Ä–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
    print("\nüîç –°–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –≤ real_dataset...")
    all_images = []
    extensions = get_image_extensions()
    
    for img_file in real_dataset_path.rglob("*"):
        if img_file.is_file() and img_file.suffix in extensions:
            all_images.append(img_file)
    
    print(f"   –ù–∞–π–¥–µ–Ω–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π: {len(all_images)}")
    
    # –§–∏–ª—å—Ç—Ä—É–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Å –º–µ—Ç–∫–∞–º–∏
    print("\nüè∑Ô∏è  –ü–æ–∏—Å–∫ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏—Ö –º–µ—Ç–æ–∫...")
    images_with_labels = []
    images_without_labels = []
    
    for img_path in all_images:
        label_path = find_matching_label(img_path, old_labels_path)
        if label_path:
            images_with_labels.append((img_path, label_path))
        else:
            images_without_labels.append(img_path)
    
    print(f"   –° –º–µ—Ç–∫–∞–º–∏: {len(images_with_labels)}")
    print(f"   –ë–µ–∑ –º–µ—Ç–æ–∫: {len(images_without_labels)}")
    
    if len(images_with_labels) == 0:
        print("\n‚ùå –û–®–ò–ë–ö–ê: –ù–µ –Ω–∞–π–¥–µ–Ω–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —Å —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–º–∏ –º–µ—Ç–∫–∞–º–∏!")
        return
    
    # –ü—Ä–æ—Å—Ç–æ–µ random —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ
    print("\nüìä –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ train/val/test...")
    random.shuffle(images_with_labels)
    
    total = len(images_with_labels)
    train_end = int(total * train_ratio)
    val_end = train_end + int(total * val_ratio)
    
    train_data = images_with_labels[:train_end]
    val_data = images_with_labels[train_end:val_end]
    test_data = images_with_labels[val_end:]
    
    splits = {
        'train': train_data,
        'val': val_data,
        'test': test_data
    }
    
    print(f"   Train: {len(train_data)} ({len(train_data)/total*100:.1f}%)")
    print(f"   Val:   {len(val_data)} ({len(val_data)/total*100:.1f}%)")
    print(f"   Test:  {len(test_data)} ({len(test_data)/total*100:.1f}%)")
    
    # –ö–æ–ø–∏—Ä—É–µ–º —Ñ–∞–π–ª—ã
    print("\nüì¶ –ö–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–æ–≤ –∏ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –º–µ—Ç–æ–∫...")
    
    stats = {'total': 0, 'converted': 0, 'skipped': 0}
    
    for split_name, data in splits.items():
        print(f"\n   {split_name}:")
        for img_path, label_path in data:
            # –ö–æ–ø–∏—Ä—É–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
            img_dst = output_path / 'images' / split_name / img_path.name
            shutil.copy2(img_path, img_dst)
            
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –º–µ—Ç–∫—É
            new_labels = convert_label_classes(label_path, CLASS_MAPPING)
            
            if len(new_labels) > 0:
                label_dst = output_path / 'labels' / split_name / (img_path.stem + '.txt')
                with open(label_dst, 'w') as f:
                    f.writelines(new_labels)
                stats['converted'] += 1
            else:
                stats['skipped'] += 1
            
            stats['total'] += 1
        
        print(f"      –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {len(data)} —Ñ–∞–π–ª–æ–≤")
    
    print(f"\n‚úÖ –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞!")
    print(f"   –í—Å–µ–≥–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {stats['total']}")
    print(f"   –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–æ –º–µ—Ç–æ–∫: {stats['converted']}")
    print(f"   –ü—Ä–æ–ø—É—â–µ–Ω–æ (–Ω–µ—Ç –∞–Ω–Ω–æ—Ç–∞—Ü–∏–π): {stats['skipped']}")
    print(f"   –í—ã—Ö–æ–¥–Ω–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è: {output_path}")
    
    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –∫–ª–∞—Å—Å–∞–º
    print("\nüìà –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –∫–ª–∞—Å—Å–∞–º:")
    class_counts = defaultdict(int)
    
    for split_name in ['train', 'val', 'test']:
        label_dir = output_path / 'labels' / split_name
        for label_file in label_dir.glob('*.txt'):
            with open(label_file, 'r') as f:
                for line in f:
                    parts = line.strip().split()
                    if len(parts) >= 5:
                        class_id = int(parts[0])
                        class_counts[class_id] += 1
    
    for class_id in sorted(class_counts.keys()):
        print(f"   –ö–ª–∞—Å—Å {class_id}: {class_counts[class_id]} –∞–Ω–Ω–æ—Ç–∞—Ü–∏–π")

if __name__ == "__main__":
    project_root = Path(__file__).parent.parent
    
    real_dataset_dir = project_root / "real_dataset"
    old_labels_dir = project_root / "dataset" / "labels"
    output_dir = project_root / "dataset_8classes"
    
    print("=" * 60)
    print("–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞ –¥–ª—è 8 –∫–ª–∞—Å—Å–æ–≤")
    print("=" * 60)
    print(f"–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {real_dataset_dir}")
    print(f"–ú–µ—Ç–∫–∏: {old_labels_dir}")
    print(f"–í—ã—Ö–æ–¥: {output_dir}")
    print("=" * 60)
    
    if not real_dataset_dir.exists():
        print(f"‚ùå –û—à–∏–±–∫–∞: –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è {real_dataset_dir} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞!")
        exit(1)
    
    if not old_labels_dir.exists():
        print(f"‚ùå –û—à–∏–±–∫–∞: –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è {old_labels_dir} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞!")
        exit(1)
    
    prepare_dataset(
        real_dataset_dir=real_dataset_dir,
        old_labels_dir=old_labels_dir,
        output_dir=output_dir,
        random_seed=42
    )

