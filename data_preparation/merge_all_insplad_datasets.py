#!/usr/bin/env python3
"""
–§–ò–ù–ê–õ–¨–ù–´–ô –°–ö–†–ò–ü–¢: –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –≤—Å–µ—Ö InsPLAD –¥–∞—Ç–∞—Å–µ—Ç–æ–≤ —Å –≤–∞—à–∏–º dataset_8classes

–û–±—ä–µ–¥–∏–Ω—è–µ—Ç:
1. InsPLAD-det (COCO ‚Üí YOLO) ‚Üí –∫–ª–∞—Å—Å—ã 0, 1, 5
2. insplad_fault_with_bbox ‚Üí –∫–ª–∞—Å—Å—ã 3, 4, 6
3. –í–∞—à dataset_8classes ‚Üí –≤—Å–µ –∫–ª–∞—Å—Å—ã

–†–µ–∑—É–ª—å—Ç–∞—Ç: –û–±–Ω–æ–≤–ª—ë–Ω–Ω—ã–π dataset_8classes —Å ~32,000+ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
"""

from pathlib import Path
import json
import shutil
from collections import defaultdict
import random

# –ú–∞–ø–ø–∏–Ω–≥ InsPLAD-det –∫–ª–∞—Å—Å–æ–≤ ‚Üí –≤–∞—à–∏ –∫–ª–∞—Å—Å—ã
INSPLAD_DET_MAPPING = {
    # Vibration dampers
    4: (0, 'vibration_damper'),     # stockbridge damper
    17: (0, 'vibration_damper'),    # spiral damper

    # Insulators - glass
    8: (1, 'festoon_insulators'),   # glass insulator
    2: (1, 'festoon_insulators'),   # yoke suspension

    # Polymer insulators
    7: (5, 'polymer_insulators'),   # polymer insulator
}


def convert_coco_to_yolo(annotation, image_info, category_mapping):
    """–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç COCO bbox –≤ YOLO format"""
    category_id = annotation['category_id']

    if category_id not in category_mapping:
        return None

    your_class_id, your_class_name = category_mapping[category_id]

    # COCO: [x, y, width, height] (top-left corner)
    x, y, w, h = annotation['bbox']
    img_w = image_info['width']
    img_h = image_info['height']

    # YOLO: [x_center, y_center, width, height] (normalized)
    x_center = (x + w / 2) / img_w
    y_center = (y + h / 2) / img_h
    norm_w = w / img_w
    norm_h = h / img_h

    # Clamp to [0, 1]
    x_center = max(0.0, min(1.0, x_center))
    y_center = max(0.0, min(1.0, y_center))
    norm_w = max(0.0, min(1.0, norm_w))
    norm_h = max(0.0, min(1.0, norm_h))

    return f"{your_class_id} {x_center:.6f} {y_center:.6f} {norm_w:.6f} {norm_h:.6f}"


def process_insplad_det(insplad_dir, output_dir):
    """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç InsPLAD-det (COCO ‚Üí YOLO)"""

    print("\n" + "="*60)
    print("üì¶ –û–ë–†–ê–ë–û–¢–ö–ê InsPLAD-det")
    print("="*60)

    stats = {'processed': 0, 'skipped': 0, 'by_class': defaultdict(int)}

    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º train –∏ val
    for split in ['train', 'val']:
        coco_file = insplad_dir / 'annotations' / f'instances_{split}.json'
        images_dir = insplad_dir / split

        if not coco_file.exists():
            print(f"‚ö†Ô∏è –ü—Ä–æ–ø—É—Å–∫–∞–µ–º {split}: {coco_file} –Ω–µ –Ω–∞–π–¥–µ–Ω")
            continue

        print(f"\nüìÇ –û–±—Ä–∞–±–æ—Ç–∫–∞ {split}...")

        # –ß–∏—Ç–∞–µ–º COCO annotations
        with open(coco_file, 'r') as f:
            coco_data = json.load(f)

        # –°–æ–∑–¥–∞—ë–º –º–∞–ø–ø–∏–Ω–≥ image_id ‚Üí image_info
        images_map = {img['id']: img for img in coco_data['images']}

        # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º annotations –ø–æ image_id
        annotations_by_image = defaultdict(list)
        for ann in coco_data['annotations']:
            annotations_by_image[ann['image_id']].append(ann)

        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∂–¥–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
        for image_id, image_info in images_map.items():
            image_filename = image_info['file_name']
            image_path = images_dir / image_filename

            if not image_path.exists():
                stats['skipped'] += 1
                continue

            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤—Å–µ annotations –¥–ª—è —ç—Ç–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
            yolo_lines = []
            for ann in annotations_by_image.get(image_id, []):
                yolo_line = convert_coco_to_yolo(ann, image_info, INSPLAD_DET_MAPPING)
                if yolo_line:
                    yolo_lines.append(yolo_line)
                    class_id = int(yolo_line.split()[0])
                    stats['by_class'][class_id] += 1

            # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –±–µ–∑ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –æ–±—ä–µ–∫—Ç–æ–≤
            if not yolo_lines:
                stats['skipped'] += 1
                continue

            # –ö–æ–ø–∏—Ä—É–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
            output_img_dir = output_dir / 'images' / split
            output_img_dir.mkdir(parents=True, exist_ok=True)

            unique_name = f"insplad_det_{split}_{image_filename}"
            output_img_path = output_img_dir / unique_name
            shutil.copy2(image_path, output_img_path)

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º label
            output_label_dir = output_dir / 'labels' / split
            output_label_dir.mkdir(parents=True, exist_ok=True)

            label_filename = Path(unique_name).stem + '.txt'
            output_label_path = output_label_dir / label_filename

            with open(output_label_path, 'w') as f:
                f.write('\n'.join(yolo_lines) + '\n')

            stats['processed'] += 1

        print(f"   ‚úì –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {stats['processed']} images")

    return stats


def merge_fault_dataset(fault_dir, output_dir):
    """–ö–æ–ø–∏—Ä—É–µ—Ç insplad_fault_with_bbox –≤ output"""

    print("\n" + "="*60)
    print("üì¶ –û–ë–™–ï–î–ò–ù–ï–ù–ò–ï insplad_fault_with_bbox")
    print("="*60)

    stats = {'processed': 0, 'skipped': 0, 'by_class': defaultdict(int)}

    if not fault_dir.exists():
        print("‚ö†Ô∏è insplad_fault_with_bbox –Ω–µ –Ω–∞–π–¥–µ–Ω, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º")
        return stats

    # –ö–æ–ø–∏—Ä—É–µ–º –≤—Å–µ splits
    for split in ['train', 'val', 'test']:
        images_dir = fault_dir / 'images' / split
        labels_dir = fault_dir / 'labels' / split

        if not images_dir.exists():
            continue

        print(f"\nüìÇ –ö–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–µ {split}...")

        # –ù–∞—Ö–æ–¥–∏–º –≤—Å–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        for img_path in images_dir.glob('*.jpg'):
            label_path = labels_dir / f"{img_path.stem}.txt"

            if not label_path.exists():
                stats['skipped'] += 1
                continue

            # –ö–æ–ø–∏—Ä—É–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
            output_img_dir = output_dir / 'images' / split
            output_img_dir.mkdir(parents=True, exist_ok=True)
            shutil.copy2(img_path, output_img_dir / img_path.name)

            # –ö–æ–ø–∏—Ä—É–µ–º label
            output_label_dir = output_dir / 'labels' / split
            output_label_dir.mkdir(parents=True, exist_ok=True)
            shutil.copy2(label_path, output_label_dir / label_path.name)

            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
            with open(label_path, 'r') as f:
                for line in f:
                    class_id = int(line.split()[0])
                    stats['by_class'][class_id] += 1

            stats['processed'] += 1

        print(f"   ‚úì –°–∫–æ–ø–∏—Ä–æ–≤–∞–Ω–æ: {stats['processed']} images")

    return stats


def merge_with_existing_dataset(source_dir, target_dir):
    """–û–±—ä–µ–¥–∏–Ω—è–µ—Ç –Ω–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ —Å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–º dataset_8classes"""

    print("\n" + "="*60)
    print("üì¶ –û–ë–™–ï–î–ò–ù–ï–ù–ò–ï –° dataset_8classes")
    print("="*60)

    if not target_dir.exists():
        print(f"‚ö†Ô∏è {target_dir} –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç, —Å–æ–∑–¥–∞—ë–º –Ω–æ–≤—ã–π")
        target_dir.mkdir(parents=True)

    stats = {'copied': 0}

    # –ö–æ–ø–∏—Ä—É–µ–º –≤—Å–µ –Ω–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
    for split in ['train', 'val', 'test']:
        source_img_dir = source_dir / 'images' / split
        source_label_dir = source_dir / 'labels' / split

        if not source_img_dir.exists():
            continue

        target_img_dir = target_dir / 'images' / split
        target_label_dir = target_dir / 'labels' / split

        target_img_dir.mkdir(parents=True, exist_ok=True)
        target_label_dir.mkdir(parents=True, exist_ok=True)

        print(f"\nüìÇ –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ {split}...")

        # –ö–æ–ø–∏—Ä—É–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        for img_path in source_img_dir.glob('*.jpg'):
            target_img_path = target_img_dir / img_path.name

            # –ï—Å–ª–∏ —Ñ–∞–π–ª —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç, –¥–æ–±–∞–≤–ª—è–µ–º prefix
            if target_img_path.exists():
                target_img_path = target_img_dir / f"new_{img_path.name}"

            shutil.copy2(img_path, target_img_path)
            stats['copied'] += 1

        # –ö–æ–ø–∏—Ä—É–µ–º labels
        for label_path in source_label_dir.glob('*.txt'):
            target_label_path = target_label_dir / label_path.name

            if target_label_path.exists():
                target_label_path = target_label_dir / f"new_{label_path.name}"

            shutil.copy2(label_path, target_label_path)

        print(f"   ‚úì –î–æ–±–∞–≤–ª–µ–Ω–æ: {stats['copied']} images")

    return stats


def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""

    print("üîÑ –§–ò–ù–ê–õ–¨–ù–û–ï –û–ë–™–ï–î–ò–ù–ï–ù–ò–ï –í–°–ï–• –î–ê–¢–ê–°–ï–¢–û–í")
    print("="*60)

    # –ü—É—Ç–∏
    base_dir = Path('.')
    insplad_det_dir = base_dir / 'InsPLAD-det'
    fault_dir = base_dir / 'insplad_fault_with_bbox'
    temp_dir = base_dir / 'temp_insplad_merged'
    final_dir = base_dir / 'dataset_8classes'

    # –°–æ–∑–¥–∞—ë–º –≤—Ä–µ–º–µ–Ω–Ω—É—é –ø–∞–ø–∫—É –¥–ª—è –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è InsPLAD –¥–∞–Ω–Ω—ã—Ö
    temp_dir.mkdir(exist_ok=True)

    # 1. –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º InsPLAD-det
    stats_det = {'processed': 0, 'by_class': defaultdict(int)}
    if insplad_det_dir.exists():
        stats_det = process_insplad_det(insplad_det_dir, temp_dir)
    else:
        print("\n‚ö†Ô∏è InsPLAD-det –Ω–µ –Ω–∞–π–¥–µ–Ω, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º")

    # 2. –ö–æ–ø–∏—Ä—É–µ–º fault dataset
    stats_fault = {'processed': 0, 'by_class': defaultdict(int)}
    if fault_dir.exists():
        stats_fault = merge_fault_dataset(fault_dir, temp_dir)
    else:
        print("\n‚ö†Ô∏è insplad_fault_with_bbox –Ω–µ –Ω–∞–π–¥–µ–Ω, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º")

    # 3. –û–±—ä–µ–¥–∏–Ω—è–µ–º —Å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–º dataset_8classes
    print("\n" + "="*60)
    print("üì¶ –§–∏–Ω–∞–ª—å–Ω–æ–µ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ...")
    print("="*60)

    merge_with_existing_dataset(temp_dir, final_dir)

    # 4. –ö–æ–ø–∏—Ä—É–µ–º YAML –∫–æ–Ω—Ñ–∏–≥
    yaml_source = base_dir / 'dataset_8classes.yaml'
    yaml_target = final_dir / 'dataset_8classes.yaml'
    if yaml_source.exists() and not yaml_target.exists():
        shutil.copy2(yaml_source, yaml_target)

    # 5. –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—É—é –ø–∞–ø–∫—É
    print("\nüóëÔ∏è –û—á–∏—Å—Ç–∫–∞ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤...")
    shutil.rmtree(temp_dir)

    # –§–ò–ù–ê–õ–¨–ù–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê
    print("\n" + "="*60)
    print("‚úÖ –û–ë–™–ï–î–ò–ù–ï–ù–ò–ï –ó–ê–í–ï–†–®–ï–ù–û!")
    print("="*60)

    print(f"\nüìä –î–û–ë–ê–í–õ–ï–ù–û –ò–ó InsPLAD:")
    print(f"   InsPLAD-det: {stats_det['processed']} images")
    print(f"   Fault datasets: {stats_fault['processed']} images")
    print(f"   –ò–¢–û–ì–û –¥–æ–±–∞–≤–ª–µ–Ω–æ: {stats_det['processed'] + stats_fault['processed']} images")

    print(f"\nüìà –î–û–ë–ê–í–õ–ï–ù–û –ü–û –ö–õ–ê–°–°–ê–ú (InsPLAD-det):")
    class_names = {
        0: 'vibration_damper',
        1: 'festoon_insulators',
        5: 'polymer_insulators',
    }
    for class_id in sorted(stats_det['by_class'].keys()):
        count = stats_det['by_class'][class_id]
        name = class_names.get(class_id, 'unknown')
        print(f"   –ö–ª–∞—Å—Å {class_id} ({name:25s}): +{count:5d}")

    print(f"\nüìà –î–û–ë–ê–í–õ–ï–ù–û –ü–û –ö–õ–ê–°–°–ê–ú (Fault):")
    fault_names = {
        3: 'bad_insulator',
        4: 'damaged_insulator',
        6: 'nest',
    }
    for class_id in sorted(stats_fault['by_class'].keys()):
        count = stats_fault['by_class'][class_id]
        name = fault_names.get(class_id, 'unknown')
        print(f"   –ö–ª–∞—Å—Å {class_id} ({name:25s}): +{count:5d}")

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
    print(f"\nüìä –§–ò–ù–ê–õ–¨–ù–´–ô –î–ê–¢–ê–°–ï–¢:")
    for split in ['train', 'val', 'test']:
        split_dir = final_dir / 'images' / split
        if split_dir.exists():
            count = len(list(split_dir.glob('*.jpg')))
            print(f"   {split:6s}: {count:5d} images")

    print(f"\nüìÇ –†–µ–∑—É–ª—å—Ç–∞—Ç: {final_dir}/")
    print("\nüí° –°–õ–ï–î–£–Æ–©–ò–ï –®–ê–ì–ò:")
    print("   1. –ò—Å–ø—Ä–∞–≤–∏—Ç—å corrupt labels: python data_preparation/fix_corrupt_labels.py")
    print("   2. –°–æ–∑–¥–∞—Ç—å –∞—Ä—Ö–∏–≤: tar -czf dataset_8classes_final.tar.gz --no-xattrs dataset_8classes/")
    print("   3. –ó–∞–≥—Ä—É–∑–∏—Ç—å –≤ Google Drive –∏ –æ–±—É—á–∏—Ç—å!")


if __name__ == '__main__':
    main()

